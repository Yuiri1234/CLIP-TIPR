# Low-Latency Privacy-Aware Robot Behavior Guided by Automatically Generated Text Datasets 
This repository is a project page of Low-Latency Privacy-Aware Robot Behavior Guided by Automatically Generated Text Datasets, and provides sample code for CLIP-driven Text-based Image Privacy Recognition (CLIP-TIPR) and example prompts for constructing the LPT dataset, as introduced in our paper.

CLIP-TIPR is a framework that leverages visionâ€“language representations to enable low-latency, privacy-aware robot behavior without requiring large-scale image-level privacy annotations.
For details of the method and experimental results, please refer to the project page and the paper.

ðŸ‘‰ Project page: https://yuiri1234.github.io/CLIP-TIPR/

## Contents

- Paper (IEEE copyright) and videos
- Sample implementation of CLIP-TIPR
- Prompts used to construct the LPT (Language-based Privacy Text) dataset

This repository is intended to support understanding and reproduction of the core ideas rather than providing a fully optimized or production-ready implementation.

## Citation
Please cite the paper if you use this code or prompts in your work.
```
@inproceedings{Irisawa2025,
    author    = {Yuta, Irisawa and Tomoaki, Yamazaki and Seiya, Ito and Shuhei, Kurita and Ryota, Akasaka and Masaki, Onishi and Kouzou, Ohara and Ken, Sakurada},
    title     = {Low-Latency Privacy-Aware Robot Behavior Guided by Automatically Generated Text Datasets},
    journal   = {IROS},
    year      = {2025}
  }
```



## Acknowledgments
This page was built using the [Academic Project Page Template](https://github.com/eliahuhorwitz/Academic-project-page-template) which was adopted from theÂ [Nerfies](https://nerfies.github.io)Â project page. You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a [Creative Commons Attribution-ShareAlike 4.0 International License](http://creativecommons.org/licenses/by-sa/4.0/).
