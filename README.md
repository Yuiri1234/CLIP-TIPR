# Low-Latency Privacy-Aware Robot Behavior Guided by Automatically Generated Text Datasets 
To realize an image privacy recognition model using only textual data with privacy indicators, it is crucial to effectively link the privacy context of a given image with private scenes described in texts. 
To this end, we propose CLIP-driven Text-based Image Privacy Recognition (CLIP-TIPR), a retrieval-based image privacy recognition model that identifies texts with privacy scores similar to the image in the CLIP's multi-modal feature space.

project page: https://yuiri1234.github.io/CLIP-TIPR/
```
@inproceedings{Irisawa2025,
    author    = {Yuta, Irisawa and Tomoaki, Yamazaki and Seiya, Ito and Shuhei, Kurita and Ryota, Akasaka and Masaki, Onishi and Kouzou, Ohara and Ken, Sakurada},
    title     = {Low-Latency Privacy-Aware Robot Behavior Guided by Automatically Generated Text Datasets},
    journal   = {IROS},
    year      = {2025}
  }
```



## Acknowledgments
This page was built using the [Academic Project Page Template](https://github.com/eliahuhorwitz/Academic-project-page-template) which was adopted from the [Nerfies](https://nerfies.github.io) project page. You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a [Creative Commons Attribution-ShareAlike 4.0 International License](http://creativecommons.org/licenses/by-sa/4.0/).
